# GPT Model Fine Tunning 

[Mastering Temperature and Top_p in ChatGPT API](https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api/172683)

These parameters are especially useful when working with GPT for tasks such as code generation, creative writing, chatbot responses, and more.

Let’s start with **temperature**:
- Temperature is a parameter that controls the “creativity” or randomness of the text generated by GPT-3. A higher temperature (e.g., 0.7) results in more diverse and creative output, while a lower temperature (e.g., 0.2) makes the output more deterministic and focused.
- In practice, temperature affects the probability distribution over the possible tokens at each step of the generation process. A temperature of 0 would make the model completely deterministic, always choosing the most likely token.

Next, let’s discuss **top_p** sampling (also known as nucleus sampling):

- Top_p sampling is an alternative to temperature sampling. Instead of considering all possible tokens, GPT-3 considers only a subset of tokens (the nucleus) whose cumulative probability mass adds up to a certain threshold (top_p).
- For example, if top_p is set to 0.1, GPT-3 will consider only the tokens that make up the top 10% of the probability mass for the next token. This allows for dynamic vocabulary selection based on context.

Both temperature and top_p sampling are powerful tools for controlling the behavior of GPT-3, and they can be used independently or together when making API calls. By adjusting these parameters, you can achieve different levels of creativity and control, making them suitable for a wide range of applications.

To give you an idea of how these parameters can be used in different scenarios, here’s a table with example values:

| Use Case|Temperature|Top_P|Description|
|---|---|---|---|
| Code Generation	| 0.2	| 0.1	| Generates code that adheres to established patterns and conventions. Output is more deterministic and focused. Useful for generating syntactically correct code. |
| Creative Writing	| 0.7	| 0.8	| Generates creative and diverse text for storytelling. Output is more exploratory and less constrained by patterns. |
| Chatbot Responses	| 0.5	| 0.5	| Generates conversational responses that balance coherence and diversity. Output is more natural and engaging. |
| Code Comment Generation	| 0.3	| 0.2	| Generates code comments that are more likely to be concise and relevant. Output is more deterministic and adheres to conventions. |
| Data Analysis Scripting	| 0.2	| 0.1	| Generates data analysis scripts that are more likely to be correct and efficient. Output is more deterministic and focused. |
| Exploratory Code Writing	| 0.6	| 0.7	| Generates code that explores alternative solutions and creative approaches. Output is less constrained by established patterns |

**OpenAI Temperature and Top**
```
#GPT model plays important role in performance improvement and response accuracy.
AZURE_OPENAI_MODEL_NAME=gpt-35-turbo-16k OR gpt-4
#Try Me Max 1
AZURE_OPENAI_TEMPERATURE=0
#Try Me less than 1.0
AZURE_OPENAI_TOP_P=1.0
#Try Me ~3000
AZURE_OPENAI_MAX_TOKENS=2000
```

**Prompt Scorer:**
Scoring system prompts against a set of prompt engineering best practices.
Prompt Scorer Rules-
```
Rule 01: The input prompt should have instructions at the beginning and context at the end.
There should be a clear delimiter indicating the start of the instructions and the end of the context.
 
Rule 02: The input prompt should give the model a persona or frame of reference
BAD EXAMPLE:  "Generate 10 integers"
GOOD EXAMPLE: "You are a math expert. Generate ten integers"
 
Rule 03: The input prompt should include details on desired output length and style
 
Rule 04: The input prompt should articulate the desired output format through examples
 
Rule 05: The input prompt should not include unprecise or ambiguous language, such as undefined articles or pronouns.
BAD EXAMPLE:  "Generate a few integers"
GOOD EXAMPLE: "Generate ten integers"
 
Rule 06: The input prompt should avoid negative statements or double negatives
BAD EXAMPLE:  "DO NOT ASK USERNAME OR PASSWORD. DO NOT REPEAT"
GOOD EXAMPLE: "Refrain from asking any questions related to PII. Instead of asking for PII, such as username or password, refer the user to the help article www.samplewebsite.com/help/faq"
 
Rule 07: The input prompt should specify the target audience or user proficiency level
BAD EXAMPLE: "Explain quantum mechanics."
GOOD EXAMPLE: "Provide a beginner-friendly explanation of quantum mechanics aimed at high school students."
 
Rule 08: The input prompt should use active voice for clarity and directness in communication.
BAD EXAMPLE: "The report should be prepared by you."
GOOD EXAMPLE: "Prepare the report."
 
Rule 09: The input prompt should end with a clear call to action that directs what the user needs to do next
BAD EXAMPLE: "Consider looking into the history of the Renaissance."
GOOD EXAMPLE: "Research the key events of the Renaissance and summarize your findings in a 300-word essay."
 
Rule 10: The input prompt should include a clear goal
BAD EXAMPLE: "Improve this code"
GOOD EXAMPLE: "Improve this code for a reduced page load time by optimizing database queries"
 
Rule 11: The input prompt should clearly state any constraints or limitations such time, culture or geographical focus, etc., to guide the response.
BAD EXAMPLE: "Write an article about climate change."
GOOD EXAMPLE: "Write a detailed 500-word article focused on the impacts of climate change in South Asia."
 
Rule 12: If the input prompt is a code generation question, it should include the desired programming language, any specific libraries or frameworks to be used and leading words to steer the desired output
 
Rule 13: If the input prompt is complex, the problem should be broken down into specific tasks. A complex prompt has more than 50 words.
 
Rule 14: If the input prompt lengths spans through multiple lines, the prompt should be broken into sections with consistent delimiters
 
Rule 15: The input prompt should not have grammar or spelling errors
 
Rule 16: The input prompt should use consistent terminology and not use synonyms for referring to the same entity
BAD EXAMPLE: "The user.... the subscriber..., the customer..."
```

**Reduce Latency in OpenAI response**
- [Enable stream](https://community.openai.com/t/gpt-3-5-turbo-instruct-stream-true-not-working/389801)
- [Implement asynchronous programming in Azure OpenAI for task Parallelization.](https://medium.com/@averma9838/implement-asynchronous-programming-in-azure-openai-for-task-parallelization-c26430491d7c)
